{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:05:16.995051Z","iopub.execute_input":"2023-09-26T06:05:16.995456Z","iopub.status.idle":"2023-09-26T06:05:17.803474Z","shell.execute_reply.started":"2023-09-26T06:05:16.995416Z","shell.execute_reply":"2023-09-26T06:05:17.802531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file = open('/kaggle/input/chula-parasite-dataset/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/labels.json')\ndata = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:05:18.854671Z","iopub.execute_input":"2023-09-26T06:05:18.857337Z","iopub.status.idle":"2023-09-26T06:05:19.075402Z","shell.execute_reply.started":"2023-09-26T06:05:18.857304Z","shell.execute_reply":"2023-09-26T06:05:19.074492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the images and their details and create a dataframe","metadata":{}},{"cell_type":"code","source":"image_df = pd.DataFrame.from_dict(pd.json_normalize(data['images']), orient='columns')\nimage_df","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:05:20.795492Z","iopub.execute_input":"2023-09-26T06:05:20.796184Z","iopub.status.idle":"2023-09-26T06:05:20.914337Z","shell.execute_reply.started":"2023-09-26T06:05:20.796151Z","shell.execute_reply":"2023-09-26T06:05:20.913236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the annotations and their details and create a dataframe","metadata":{}},{"cell_type":"code","source":"annotation_df = pd.DataFrame.from_dict(pd.json_normalize(data['annotations']), orient='columns')\nannotation_df","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:05:22.554587Z","iopub.execute_input":"2023-09-26T06:05:22.555256Z","iopub.status.idle":"2023-09-26T06:05:22.650188Z","shell.execute_reply.started":"2023-09-26T06:05:22.555225Z","shell.execute_reply":"2023-09-26T06:05:22.649201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicate_values = annotation_df['image_id'].duplicated()\nduplicate_values","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:05:23.324679Z","iopub.execute_input":"2023-09-26T06:05:23.325360Z","iopub.status.idle":"2023-09-26T06:05:23.343318Z","shell.execute_reply.started":"2023-09-26T06:05:23.325328Z","shell.execute_reply":"2023-09-26T06:05:23.342160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merging the above two dataframe\nMerged using the image_id column","metadata":{}},{"cell_type":"code","source":"merged_df = pd.merge(image_df, annotation_df, left_on='id', right_on='image_id', how='inner')\n\n# Drop the extra 'image_id' column as it's now redundant\nmerged_df.drop(columns=['image_id'], inplace=True)\nmerged_df","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:05:24.934550Z","iopub.execute_input":"2023-09-26T06:05:24.935642Z","iopub.status.idle":"2023-09-26T06:05:24.969841Z","shell.execute_reply.started":"2023-09-26T06:05:24.935601Z","shell.execute_reply":"2023-09-26T06:05:24.968762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seperating features and target variables","metadata":{}},{"cell_type":"code","source":"X = merged_df[['id_x','file_name','height','width','area']]\n#y = merged_df[['category_id','bbox']]\ny = merged_df['category_id']","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:43.074805Z","iopub.execute_input":"2023-09-26T06:13:43.075208Z","iopub.status.idle":"2023-09-26T06:13:43.082287Z","shell.execute_reply.started":"2023-09-26T06:13:43.075177Z","shell.execute_reply":"2023-09-26T06:13:43.081001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:44.074645Z","iopub.execute_input":"2023-09-26T06:13:44.075033Z","iopub.status.idle":"2023-09-26T06:13:44.091118Z","shell.execute_reply.started":"2023-09-26T06:13:44.075003Z","shell.execute_reply":"2023-09-26T06:13:44.090075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:44.999420Z","iopub.execute_input":"2023-09-26T06:13:45.000223Z","iopub.status.idle":"2023-09-26T06:13:45.009476Z","shell.execute_reply.started":"2023-09-26T06:13:45.000182Z","shell.execute_reply":"2023-09-26T06:13:45.008400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spliting the traning and testing sets","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,shuffle=True,test_size=0.2)\nX_test,X_val,y_test,y_val = train_test_split(X_test,y_test,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:46.664622Z","iopub.execute_input":"2023-09-26T06:13:46.665834Z","iopub.status.idle":"2023-09-26T06:13:46.676508Z","shell.execute_reply.started":"2023-09-26T06:13:46.665791Z","shell.execute_reply":"2023-09-26T06:13:46.675511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ultralytics --quiet","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:47.334592Z","iopub.execute_input":"2023-09-26T06:13:47.335511Z","iopub.status.idle":"2023-09-26T06:13:59.297515Z","shell.execute_reply.started":"2023-09-26T06:13:47.335469Z","shell.execute_reply":"2023-09-26T06:13:59.296157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport cv2 as cv\nfrom ultralytics import YOLO","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:59.299928Z","iopub.execute_input":"2023-09-26T06:13:59.300249Z","iopub.status.idle":"2023-09-26T06:13:59.306920Z","shell.execute_reply.started":"2023-09-26T06:13:59.300219Z","shell.execute_reply":"2023-09-26T06:13:59.305781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = YOLO('yolov8n-seg.pt')","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:59.308112Z","iopub.execute_input":"2023-09-26T06:13:59.309674Z","iopub.status.idle":"2023-09-26T06:13:59.378710Z","shell.execute_reply.started":"2023-09-26T06:13:59.309640Z","shell.execute_reply":"2023-09-26T06:13:59.377745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.preprocessing import image\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:59.381042Z","iopub.execute_input":"2023-09-26T06:13:59.381479Z","iopub.status.idle":"2023-09-26T06:13:59.386421Z","shell.execute_reply.started":"2023-09-26T06:13:59.381444Z","shell.execute_reply":"2023-09-26T06:13:59.385326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:59.388176Z","iopub.execute_input":"2023-09-26T06:13:59.389151Z","iopub.status.idle":"2023-09-26T06:13:59.400851Z","shell.execute_reply.started":"2023-09-26T06:13:59.389118Z","shell.execute_reply":"2023-09-26T06:13:59.399612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = y_train.astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:13:59.402524Z","iopub.execute_input":"2023-09-26T06:13:59.402978Z","iopub.status.idle":"2023-09-26T06:13:59.409873Z","shell.execute_reply.started":"2023-09-26T06:13:59.402946Z","shell.execute_reply":"2023-09-26T06:13:59.408895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_path = '/kaggle/input/chula-parasite-dataset/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/data'\nX_train['abs_file_name'] = X_train['file_name'].apply(lambda x:dir_path + '/' + x)\n#print(filenames)\nfilenames = tf.constant(X_train['abs_file_name'])\nprint(filenames)\nlabels = tf.constant(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:49:14.989635Z","iopub.execute_input":"2023-09-26T06:49:14.990038Z","iopub.status.idle":"2023-09-26T06:49:15.006866Z","shell.execute_reply.started":"2023-09-26T06:49:14.990009Z","shell.execute_reply":"2023-09-26T06:49:15.005766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:38:57.271129Z","iopub.execute_input":"2023-09-26T06:38:57.271592Z","iopub.status.idle":"2023-09-26T06:38:57.284358Z","shell.execute_reply.started":"2023-09-26T06:38:57.271555Z","shell.execute_reply":"2023-09-26T06:38:57.283179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames[0]\n#train_dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:47:52.860619Z","iopub.execute_input":"2023-09-26T06:47:52.861057Z","iopub.status.idle":"2023-09-26T06:47:52.869905Z","shell.execute_reply.started":"2023-09-26T06:47:52.861024Z","shell.execute_reply":"2023-09-26T06:47:52.868690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset\nfilenames = X['file_name']","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:50:47.311328Z","iopub.execute_input":"2023-09-26T06:50:47.311745Z","iopub.status.idle":"2023-09-26T06:50:47.317085Z","shell.execute_reply.started":"2023-09-26T06:50:47.311689Z","shell.execute_reply":"2023-09-26T06:50:47.316042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ndef yolo_loss(y_true, y_pred):\n    # Extract the components from y_true and y_pred\n    true_coords = y_true[..., :4]  # Ground truth bounding box coordinates\n    pred_coords = y_pred[..., :4]  # Predicted bounding box coordinates\n    true_obj_conf = y_true[..., 4:5]  # Ground truth objectness confidence\n    pred_obj_conf = y_pred[..., 4:5]  # Predicted objectness confidence\n    true_class_probs = y_true[..., 5:]  # Ground truth class probabilities\n    pred_class_probs = y_pred[..., 5:]  # Predicted class probabilities\n\n    # Define the loss components\n    localization_loss = tf.reduce_sum(tf.square(true_coords - pred_coords), axis=-1)\n    objectness_loss = tf.reduce_sum(tf.square(true_obj_conf - pred_obj_conf), axis=-1)\n    classification_loss = tf.reduce_sum(tf.square(true_class_probs - pred_class_probs), axis=-1)\n\n    # Weight the loss components as needed\n    # You can adjust the weights based on your problem's requirements\n    lambda_coord = 5.0\n    lambda_noobj = 0.5\n\n    total_loss = (\n        lambda_coord * tf.reduce_sum(localization_loss) +\n        tf.reduce_sum(objectness_loss) +\n        lambda_noobj * tf.reduce_sum(objectness_loss) +\n        tf.reduce_sum(classification_loss)\n    )\n\n    return total_loss\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:50:48.622309Z","iopub.execute_input":"2023-09-26T06:50:48.622725Z","iopub.status.idle":"2023-09-26T06:50:48.632076Z","shell.execute_reply.started":"2023-09-26T06:50:48.622673Z","shell.execute_reply":"2023-09-26T06:50:48.631007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss function and optimizer\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nleng = len(filenames)\n# Training loop\nepochs = 10  # You can adjust this\nfor epoch in range(epochs):\n    for image in filenames:\n        #print(image.dtype)\n        with tf.GradientTape() as tape:\n            #image = image.numpy()[0].decode('utf-8')\n            image = cv.imread(image)\n            predictions = model(image)\n            loss = yolo_loss(label, predictions)\n        \n        gradients = tape.gradient(loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    \n    # Optionally, you can print or log the loss for each epoch\n    print(f\"Epoch {epoch + 1}, Loss: {loss.numpy()}\")\n\n# Save the trained model if needed\nmodel.save('trained_yolo_model')","metadata":{"execution":{"iopub.status.busy":"2023-09-26T06:51:03.599907Z","iopub.execute_input":"2023-09-26T06:51:03.600308Z","iopub.status.idle":"2023-09-26T06:51:06.765682Z","shell.execute_reply.started":"2023-09-26T06:51:03.600277Z","shell.execute_reply":"2023-09-26T06:51:06.764158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Below code should be changed.","metadata":{}},{"cell_type":"markdown","source":"## Resizing images into one size","metadata":{}},{"cell_type":"code","source":"image_height = 299\nimage_width = 299 \nbatch_size = 8","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:02:23.887665Z","iopub.execute_input":"2023-09-22T17:02:23.888046Z","iopub.status.idle":"2023-09-22T17:02:23.892749Z","shell.execute_reply.started":"2023-09-22T17:02:23.888013Z","shell.execute_reply":"2023-09-22T17:02:23.891657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2 as cv","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:02:24.649313Z","iopub.execute_input":"2023-09-22T17:02:24.650085Z","iopub.status.idle":"2023-09-22T17:02:24.832764Z","shell.execute_reply.started":"2023-09-22T17:02:24.650048Z","shell.execute_reply":"2023-09-22T17:02:24.831794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_path = '/kaggle/input/chula-parasite-dataset/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/data'\n\nimg = cv.imread(\"/kaggle/input/chula-parasite-dataset/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/Chula-ParasiteEgg-11/data/Ascaris lumbricoides_0003.jpg\")\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:03:10.413504Z","iopub.execute_input":"2023-09-22T17:03:10.413868Z","iopub.status.idle":"2023-09-22T17:03:11.027682Z","shell.execute_reply.started":"2023-09-22T17:03:10.413836Z","shell.execute_reply":"2023-09-22T17:03:11.026846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from tqdm import tqdm\nimport tensorflow as tf\nfrom keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:03:21.958413Z","iopub.execute_input":"2023-09-22T17:03:21.958789Z","iopub.status.idle":"2023-09-22T17:03:29.753110Z","shell.execute_reply.started":"2023-09-22T17:03:21.958759Z","shell.execute_reply":"2023-09-22T17:03:29.752111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['abs_file_name'] = X_train['file_name'].apply(lambda x:dir_path + '/' + x)\nfilenames = tf.constant(X_train['abs_file_name'])\nlabels = tf.constant(y_train)\n\ndef one_hot_encode(label):\n    encoding = []\n    for i in range(int(label)):\n        encoding.append(0)\n    encoding.append(1)\n    for j in range(int(10-int(label))):\n        encoding.append(0)\n    return tf.convert_to_tensor(encoding,dtype=tf.float32)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n\ndef im_file_to_tensor(file, label):\n    image = tf.io.read_file(file)\n    image_decoded = tf.image.decode_image(image, channels=3,dtype=tf.float32,expand_animations = False)\n#     im = image_decoded / 255.0\n    im = tf.keras.preprocessing.image.smart_resize(image_decoded, (image_height,image_width), interpolation='bilinear')\n#     im = tf.image.resize(im,,preserve_aspect_ratio=True)\n    label = tf.one_hot(label,depth=11)\n    return im, label\n\n    \n\ntrain_dataset = train_dataset.map(im_file_to_tensor)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:03:39.763621Z","iopub.execute_input":"2023-09-22T17:03:39.764297Z","iopub.status.idle":"2023-09-22T17:03:43.143914Z","shell.execute_reply.started":"2023-09-22T17:03:39.764262Z","shell.execute_reply":"2023-09-22T17:03:43.142916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train_dataset:\n    #display(i[0].numpy())\n    break","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:03:47.148235Z","iopub.execute_input":"2023-09-22T17:03:47.148623Z","iopub.status.idle":"2023-09-22T17:03:47.389366Z","shell.execute_reply.started":"2023-09-22T17:03:47.148591Z","shell.execute_reply":"2023-09-22T17:03:47.388218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batched_dataset = train_dataset.batch(batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:03:50.001647Z","iopub.execute_input":"2023-09-22T17:03:50.002791Z","iopub.status.idle":"2023-09-22T17:03:50.012471Z","shell.execute_reply.started":"2023-09-22T17:03:50.002753Z","shell.execute_reply":"2023-09-22T17:03:50.011434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val['abs_file_name'] = X_val['file_name'].apply(lambda x:dir_path + '/' + x)\nfilenames = tf.constant(X_val['abs_file_name'])\nlabels = tf.constant(y_val)\n\neval_dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n\n# def im_file_to_tensor(file, label):\n#     image = tf.io.read_file(file)\n#     image_decoded = tf.image.decode_image(image, channels=3,dtype=tf.float32,expand_animations = False)\n# #     im = image_decoded / 255.0\n#     im = tf.keras.preprocessing.image.smart_resize(image_decoded, (image_height,image_width), interpolation='bilinear')\n#     label = one_hot_encode(label)\n#     return im, label\n    \n\neval_dataset = eval_dataset.map(im_file_to_tensor)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:03:52.965241Z","iopub.execute_input":"2023-09-22T17:03:52.965591Z","iopub.status.idle":"2023-09-22T17:03:53.016184Z","shell.execute_reply.started":"2023-09-22T17:03:52.965563Z","shell.execute_reply":"2023-09-22T17:03:53.015241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_batched_dataset = eval_dataset.batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:03:55.217725Z","iopub.execute_input":"2023-09-22T17:03:55.218105Z","iopub.status.idle":"2023-09-22T17:03:55.224192Z","shell.execute_reply.started":"2023-09-22T17:03:55.218074Z","shell.execute_reply":"2023-09-22T17:03:55.223190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:03:57.728569Z","iopub.execute_input":"2023-09-22T17:03:57.728953Z","iopub.status.idle":"2023-09-22T17:03:57.734959Z","shell.execute_reply.started":"2023-09-22T17:03:57.728921Z","shell.execute_reply":"2023-09-22T17:03:57.734042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_trained_model = InceptionV3(input_shape=(image_height,image_width,3),\n                               include_top=False,\n                                weights='imagenet'\n                               )","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:03:58.932802Z","iopub.execute_input":"2023-09-22T17:03:58.933209Z","iopub.status.idle":"2023-09-22T17:04:02.806619Z","shell.execute_reply.started":"2023-09-22T17:03:58.933181Z","shell.execute_reply":"2023-09-22T17:04:02.805624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in pre_trained_model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:04:02.808403Z","iopub.execute_input":"2023-09-22T17:04:02.809465Z","iopub.status.idle":"2023-09-22T17:04:02.831543Z","shell.execute_reply.started":"2023-09-22T17:04:02.809428Z","shell.execute_reply":"2023-09-22T17:04:02.830674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import Callback","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:04:13.617942Z","iopub.execute_input":"2023-09-22T17:04:13.618468Z","iopub.status.idle":"2023-09-22T17:04:13.629042Z","shell.execute_reply.started":"2023-09-22T17:04:13.618430Z","shell.execute_reply":"2023-09-22T17:04:13.627727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = layers.Flatten()(pre_trained_model.output)\nx = layers.Dense(256,activation='relu')(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Dense(11,activation='softmax')(x)\nmodel = Model(pre_trained_model.input,x)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:04:14.886007Z","iopub.execute_input":"2023-09-22T17:04:14.886369Z","iopub.status.idle":"2023-09-22T17:04:14.968172Z","shell.execute_reply.started":"2023-09-22T17:04:14.886340Z","shell.execute_reply":"2023-09-22T17:04:14.967204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train_batched_dataset:\n    #print(i)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:04:18.368580Z","iopub.execute_input":"2023-09-22T17:04:18.369256Z","iopub.status.idle":"2023-09-22T17:04:19.564239Z","shell.execute_reply.started":"2023-09-22T17:04:18.369216Z","shell.execute_reply":"2023-09-22T17:04:19.563146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n    generator=train_batched_dataset,\n    validation_data=eval_batched_dataset,\n    steps_per_epoch=100,\n    epochs=100,\n    validation_steps=50,\n)\n","metadata":{"execution":{"iopub.execute_input":"2022-04-17T17:18:39.154729Z","iopub.status.busy":"2022-04-17T17:18:39.154415Z","iopub.status.idle":"2022-04-17T17:32:04.961201Z","shell.execute_reply":"2022-04-17T17:32:04.960425Z","shell.execute_reply.started":"2022-04-17T17:18:39.154693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#1. use adam instead of rms","metadata":{"execution":{"iopub.execute_input":"2022-04-17T17:32:04.964771Z","iopub.status.busy":"2022-04-17T17:32:04.964534Z","iopub.status.idle":"2022-04-17T17:32:04.967725Z","shell.execute_reply":"2022-04-17T17:32:04.967074Z","shell.execute_reply.started":"2022-04-17T17:32:04.964737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use efficient net\n# set seed - numpy,tf,random\n#tune learning rate, try learning rate schedulers\n# input pipeline:prefetch, tf.func-->/255 in tf func ani decode vagare in another\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## YOLO model testing","metadata":{}},{"cell_type":"code","source":"pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2023-10-03T09:19:04.207975Z","iopub.execute_input":"2023-10-03T09:19:04.208404Z","iopub.status.idle":"2023-10-03T09:19:16.996630Z","shell.execute_reply.started":"2023-10-03T09:19:04.208380Z","shell.execute_reply":"2023-10-03T09:19:16.995270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing with a sample image","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO('yolov8n.pt')\nmodel.predict(\n   source='https://media.roboflow.com/notebooks/examples/dog.jpeg',\n   conf=0.25\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T09:19:24.311862Z","iopub.execute_input":"2023-10-03T09:19:24.312211Z","iopub.status.idle":"2023-10-03T09:19:37.317744Z","shell.execute_reply.started":"2023-10-03T09:19:24.312178Z","shell.execute_reply":"2023-10-03T09:19:37.316719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO('yolov8n.yaml')  # build a new model from YAML\nmodel = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\nmodel = YOLO('yolov8n.yaml').load('yolov8n.pt')  # build from YAML and transfer weights\n\n# Train the model\nresults = model.train(data='/kaggle/input/testing1-yaml/egg.yaml', epochs=2, imgsz=640)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T09:49:49.206393Z","iopub.execute_input":"2023-10-03T09:49:49.207382Z","iopub.status.idle":"2023-10-03T09:50:57.130876Z","shell.execute_reply.started":"2023-10-03T09:49:49.207338Z","shell.execute_reply":"2023-10-03T09:50:57.126239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}